# streamlit_app.py â€” Báº£n Ä‘Ã£ sá»­a lá»—i vÃ  thÃªm zoom theo nÄƒm + dá»± bÃ¡o tÆ°Æ¡ng lai
import os, time, math, warnings, random, io
warnings.filterwarnings("ignore")

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import streamlit as st
import tensorflow as tf
from tensorflow.keras import layers, models, callbacks
from sklearn.preprocessing import MinMaxScaler

# =========================
# Page config & theming
# =========================
st.set_page_config(page_title="Gold Price LSTM Dashboard", layout="wide")
st.title("ğŸ“ˆ Dá»± bÃ¡o giÃ¡ vÃ ng vá»›i LSTM â€” Äá»“ Ã¡n KHDL")
st.caption("TÆ°Æ¡ng tÃ¡c: táº£i dá»¯ liá»‡u, cáº¥u hÃ¬nh tham sá»‘, huáº¥n luyá»‡n, xem biá»ƒu Ä‘á»“ & táº£i káº¿t quáº£.")

# Reproducibility
SEED = 42
random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)

# =========================
# Sidebar â€” cáº¥u hÃ¬nh
# =========================
st.sidebar.header("âš™ï¸ Cáº¥u hÃ¬nh")
DEFAULT_PATH = "/content/drive/MyDrive/ÄoÌ‚Ì€ aÌn/ÄoÌ‚Ì€ aÌn chuyeÌ‚n ngaÌ€nh KHDL/Gold Price (2013-2023).csv"

uploaded = st.sidebar.file_uploader("Táº£i CSV (tÃ¹y chá»n)", type=["csv"]) 
use_default = st.sidebar.checkbox("DÃ¹ng Ä‘Æ°á»ng dáº«n máº·c Ä‘á»‹nh", value=False)
custom_path = st.sidebar.text_input("hoáº·c nháº­p Ä‘Æ°á»ng dáº«n CSV", value="")

DATE_COL = st.sidebar.text_input("TÃªn cá»™t ngÃ y", value="Date")
PRICE_COL = st.sidebar.text_input("TÃªn cá»™t giÃ¡", value="Price")
TRAIN_END = st.sidebar.text_input("Má»‘c chia Train/Test (YYYY-MM-DD)", value="2021-12-31")
LOOKBACK   = st.sidebar.number_input("LOOKBACK (cá»­a sá»• chuá»—i)", min_value=10, max_value=365, value=60, step=5)
EPOCHS     = st.sidebar.number_input("EPOCHS", min_value=1, max_value=500, value=120, step=5)
BATCH      = st.sidebar.number_input("BATCH SIZE", min_value=1, max_value=512, value=32, step=1)
VERBOSE    = st.sidebar.selectbox("Verbose", options=[0,1,2], index=1)

st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ”® Dá»± bÃ¡o tÆ°Æ¡ng lai")
PRESET = st.sidebar.selectbox("Chá»n nhanh", options=["5 ngÃ y","10 ngÃ y","1 thÃ¡ng (30)","TÃ¹y chá»‰nh"], index=0)
if PRESET == "5 ngÃ y":
    FORECAST_DAYS = 5
elif PRESET == "10 ngÃ y":
    FORECAST_DAYS = 10
elif PRESET == "1 thÃ¡ng (30)":
    FORECAST_DAYS = 30
else:
    FORECAST_DAYS = st.sidebar.number_input("Sá»‘ ngÃ y dá»± bÃ¡o", min_value=1, max_value=365, value=7, step=1)

PLOT_START_YEAR = st.sidebar.number_input("Hiá»ƒn thá»‹ biá»ƒu Ä‘á»“ tá»« nÄƒm", min_value=2000, max_value=2100, value=2020, step=1)

col_btn1, col_btn2 = st.sidebar.columns(2)
train_btn = col_btn1.button("ğŸš€ Train")
reset_btn = col_btn2.button("ğŸ”„ Reset")

SAVE_DIR = "outputs"
os.makedirs(SAVE_DIR, exist_ok=True)

# =========================
# Helper functions
# =========================

def clean_numeric_cell(s):
    if pd.isna(s):
        return np.nan
    s = str(s).strip().replace("$","").replace("â‚¬","").replace("%","").replace("K","000")
    s = s.replace(",", "")
    if s in ["", "-", "null", "None", "NaN", "â€”", "â€“"]:
        return np.nan
    try:
        return float(s)
    except Exception:
        s2 = s.replace(".", "").replace(",", ".")
        try:
            return float(s2)
        except Exception:
            return np.nan

@st.cache_data(show_spinner=False)
def load_data(file_obj_or_path, date_col, price_col):
    if file_obj_or_path is None:
        raise ValueError("ChÆ°a cung cáº¥p dá»¯ liá»‡u CSV.")
    df = pd.read_csv(file_obj_or_path)
    if date_col not in df.columns or price_col not in df.columns:
        raise ValueError(f"KhÃ´ng tÃ¬m tháº¥y cá»™t '{date_col}' hoáº·c '{price_col}' trong CSV.")
    df[date_col] = pd.to_datetime(df[date_col], errors="coerce")
    df[price_col] = df[price_col].apply(clean_numeric_cell).astype(float)
    data = df[[date_col, price_col]].dropna().sort_values(date_col).reset_index(drop=True)
    data = data.rename(columns={date_col: "date", price_col: "close"})
    return data

@st.cache_data(show_spinner=False)
def make_sequences(data_df, lookback, train_end):
    from collections import deque
    sc_close = MinMaxScaler()
    train = data_df[data_df["date"] <= pd.to_datetime(train_end)].copy()
    sc_close.fit(train[["close"]].values)

    close_all_scaled = pd.Series(
        sc_close.transform(data_df[["close"]].values).ravel(),
        index=data_df["date"], name="close_scaled"
    )
    y_scaled = close_all_scaled.shift(-1)

    Xs, ys, idx = [], [], []
    dq = deque(maxlen=lookback)
    for t, v in close_all_scaled.items():
        dq.append(v)
        if len(dq) == lookback:
            yv = y_scaled.loc[t]
            if np.isnan(yv):
                break
            Xs.append(np.array(dq))
            ys.append(yv)
            idx.append(t)

    X_all = np.array(Xs)
    y_all = np.array(ys)
    idx_all = pd.DatetimeIndex(idx)

    mask_train = idx_all <= pd.to_datetime(train_end)
    X_train, y_train = X_all[mask_train], y_all[mask_train]
    X_test,  y_test  = X_all[~mask_train], y_all[~mask_train]
    idx_test = idx_all[~mask_train]

    X_train = X_train.reshape(-1, lookback, 1)
    X_test  = X_test.reshape(-1, lookback, 1)

    return sc_close, (X_train, y_train), (X_test, y_test), idx_test


def build_lstm_model(lookback):
    model = models.Sequential([
        layers.Input(shape=(lookback, 1)),
        layers.LSTM(128, return_sequences=True),
        layers.Dropout(0.3),
        layers.LSTM(64),
        layers.Dropout(0.3),
        layers.Dense(32, activation="relu"),
        layers.Dense(1)
    ])
    model.compile(optimizer="adam", loss="mse")
    return model


def plot_performance(data_df, train_end, idx_test, y_pred, title="Model Performance on Gold Price Prediction (LSTM)"):
    close = data_df.set_index("date")["close"]
    fig, ax = plt.subplots(figsize=(12,4))
    ax.set_facecolor("#fff59d")
    ax.plot(close.loc[:train_end].index, close.loc[:train_end], color="black", label="Training Data")
    ax.plot(close.loc[train_end:].index, close.loc[train_end:], color="blue",  label="Actual Test Data")
    ax.plot(idx_test, y_pred, color="red", label="Predicted Test Data")
    ax.set_title(title)
    ax.set_xlabel("Date"); ax.set_ylabel("Price")
    ax.legend(); fig.tight_layout()
    return fig


def forecast_future(model, scaler, data_df, lookback, n_days):
    """Dá»± bÃ¡o n bÆ°á»›c tá»›i báº±ng phÆ°Æ¡ng phÃ¡p cuá»™n (recursive)."""
    series_scaled = scaler.transform(data_df[["close"]].values).ravel()
    window = series_scaled[-lookback:].tolist()
    preds = []
    dates = []
    last_date = data_df["date"].iloc[-1]

    for i in range(n_days):
        x = np.array(window[-lookback:]).reshape(1, lookback, 1)
        y_scaled = model.predict(x, verbose=0).ravel()[0]
        y = scaler.inverse_transform([[y_scaled]]).ravel()[0]
        preds.append(y)
        dates.append(last_date + pd.Timedelta(days=i+1))
        window.append(y_scaled)

    return pd.DataFrame({"date": dates, "forecast": preds})

# =========================
# Main app flow
# =========================

# Resolve data source
csv_source = None
if uploaded is not None:
    csv_source = uploaded
elif use_default:
    if os.path.exists(DEFAULT_PATH):
        csv_source = DEFAULT_PATH
    else:
        st.warning("KhÃ´ng tÃ¬m tháº¥y file máº·c Ä‘á»‹nh. HÃ£y táº£i CSV hoáº·c nháº­p Ä‘Æ°á»ng dáº«n há»£p lá»‡.")
elif custom_path:
    if os.path.exists(custom_path):
        csv_source = custom_path
    else:
        st.warning("ÄÆ°á»ng dáº«n CSV khÃ´ng tá»“n táº¡i.")

# Session state reset
if reset_btn:
    for k in ["data", "scaler", "X_train", "y_train", "X_test", "y_test", "idx_test", "model", "history", "metrics", "pred_df", "future_df"]:
        if k in st.session_state:
            del st.session_state[k]
    st.experimental_rerun()

# 1) Load & preview
if csv_source is not None and "data" not in st.session_state:
    with st.spinner("Äang táº£i & tiá»n xá»­ lÃ½ dá»¯ liá»‡uâ€¦"):
        try:
            data = load_data(csv_source, DATE_COL, PRICE_COL)
            st.session_state.data = data
        except Exception as e:
            st.error(f"Lá»—i dá»¯ liá»‡u: {e}")

if "data" in st.session_state:
    data = st.session_state.data
    c1, c2 = st.columns([2,1])
    with c1:
        st.subheader("ğŸ‘€ Máº«u dá»¯ liá»‡u")
        st.dataframe(data.head(10), use_container_width=True)
    with c2:
        st.metric("Sá»‘ dÃ²ng", len(data))
        st.write("Khoáº£ng thá»i gian:", data["date"].min().date(), "â†’", data["date"].max().date())

    # 2) Make sequences
    if "X_train" not in st.session_state:
        with st.spinner("Äang táº¡o chuá»—i (sequences)â€¦"):
            sc_close, (X_train, y_train), (X_test, y_test), idx_test = make_sequences(data, LOOKBACK, TRAIN_END)
            st.session_state.scaler = sc_close
            st.session_state.X_train, st.session_state.y_train = X_train, y_train
            st.session_state.X_test,  st.session_state.y_test  = X_test, y_test
            st.session_state.idx_test = idx_test

    # 3) Train
    if train_btn:
        X_train = st.session_state.X_train; y_train = st.session_state.y_train
        X_test  = st.session_state.X_test;  y_test  = st.session_state.y_test
        if X_train.size == 0 or X_test.size == 0:
            st.error("KhÃ´ng Ä‘á»§ dá»¯ liá»‡u train/test. HÃ£y kiá»ƒm tra TRAIN_END hoáº·c LOOKBACK.")
        else:
            cb_list = [
                callbacks.ReduceLROnPlateau(factor=0.5, patience=5, verbose=1, monitor="val_loss"),
                callbacks.EarlyStopping(patience=10, restore_best_weights=True, monitor="val_loss", verbose=1),
            ]
            model = build_lstm_model(LOOKBACK)
            t0 = time.perf_counter()
            with st.spinner("Äang huáº¥n luyá»‡n mÃ´ hÃ¬nhâ€¦"):
                hist = model.fit(
                    X_train, y_train,
                    validation_split=0.15,
                    epochs=EPOCHS,
                    batch_size=BATCH,
                    verbose=VERBOSE,
                    callbacks=cb_list
                )
            train_time = time.perf_counter() - t0

            st.session_state.model = model
            st.session_state.history = hist.history

            # 4) Predict & inverse transform (test)
            y_pred_scaled = model.predict(st.session_state.X_test, verbose=0).ravel()
            y_pred = st.session_state.scaler.inverse_transform(y_pred_scaled.reshape(-1,1)).ravel()
            y_true = st.session_state.scaler.inverse_transform(st.session_state.y_test.reshape(-1,1)).ravel()

            # 5) Metrics
            rmse = math.sqrt(np.mean((y_true - y_pred)**2))
            mae  = np.mean(np.abs(y_true - y_pred))
            mape = np.mean(np.abs((y_true - y_pred)/(y_true+1e-9))) * 100
            metrics = {"RMSE": float(rmse), "MAE": float(mae), "MAPE_%": float(mape), "Train_Time_s": round(train_time,1)}
            st.session_state.metrics = metrics

            # 6) Pred DataFrame
            pred_df = pd.DataFrame({
                "date": st.session_state.idx_test,
                "y_true": y_true,
                "y_pred": y_pred
            })
            st.session_state.pred_df = pred_df

            # 7) Future forecast ngay sau khi train
            st.session_state.future_df = forecast_future(
                model, st.session_state.scaler, st.session_state.data, LOOKBACK, FORECAST_DAYS
            )

    # 4) Show results
    if "metrics" in st.session_state and "pred_df" in st.session_state:
        m = st.session_state.metrics
        pred_df = st.session_state.pred_df
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("RMSE", f"{m['RMSE']:.2f}")
        c2.metric("MAE", f"{m['MAE']:.2f}")
        c3.metric("MAPE", f"{m['MAPE_%']:.2f}%")
        c4.metric("Thá»i gian train", f"{m['Train_Time_s']:.1f}s")

        # Plot test performance
        fig = plot_performance(st.session_state.data, TRAIN_END, st.session_state.idx_test, pred_df["y_pred"].values)
        st.pyplot(fig, use_container_width=True)

        # Learning curve
        if "history" in st.session_state:
            hist = st.session_state.history
            if "loss" in hist and "val_loss" in hist:
                fig2, ax2 = plt.subplots(figsize=(12,3))
                ax2.plot(hist["loss"], label="loss")
                ax2.plot(hist["val_loss"], label="val_loss")
                ax2.set_title("Learning Curve"); ax2.set_xlabel("epoch"); ax2.set_ylabel("MSE")
                ax2.legend(); fig2.tight_layout()
                st.pyplot(fig2, use_container_width=True)


        # Downloads (metrics & test predictions)
        col_a, col_b = st.columns(2)
        with col_a:
            st.download_button(
                label="â¬‡ï¸ Táº£i metrics.json",
                data=io.BytesIO(pd.Series(m).to_json().encode()),
                file_name="metrics.json",
                mime="application/json"
            )
        with col_b:
            csv_bytes = pred_df.to_csv(index=False).encode()
            st.download_button(
                label="â¬‡ï¸ Táº£i predictions.csv",
                data=csv_bytes,
                file_name="predictions.csv",
                mime="text/csv"
            )

        # Save/Load model (optional)
        with st.expander("ğŸ’¾ LÆ°u/Load mÃ´ hÃ¬nh (tÃ¹y chá»n)"):
            save_col, load_col = st.columns(2)
            if save_col.button("LÆ°u mÃ´ hÃ¬nh vÃ o outputs/model.keras"):
                try:
                    st.session_state.model.save(os.path.join(SAVE_DIR, "model.keras"))
                    st.success("ÄÃ£ lÆ°u mÃ´ hÃ¬nh.")
                except Exception as e:
                    st.error(f"KhÃ´ng thá»ƒ lÆ°u mÃ´ hÃ¬nh: {e}")
            uploaded_weights = load_col.file_uploader("Táº£i file model.keras Ä‘á»ƒ load láº¡i", type=["keras"], key="uploader_model")
            if uploaded_weights is not None and st.button("Load mÃ´ hÃ¬nh Ä‘Ã£ táº£i"):
                try:
                    with open(os.path.join(SAVE_DIR, "tmp_model.keras"), "wb") as f:
                        f.write(uploaded_weights.read())
                    st.session_state.model = tf.keras.models.load_model(os.path.join(SAVE_DIR, "tmp_model.keras"))
                    st.success("ÄÃ£ load mÃ´ hÃ¬nh.")
                except Exception as e:
                    st.error(f"KhÃ´ng thá»ƒ load mÃ´ hÃ¬nh: {e}")

else:
    st.info("â¡ï¸ HÃ£y táº£i CSV, chá»n dÃ¹ng file máº·c Ä‘á»‹nh, hoáº·c nháº­p Ä‘Æ°á»ng dáº«n rá»“i nháº¥n **Train**.")

st.markdown("---")
st.caption("Gá»£i Ã½: Deploy dá»… dÃ ng vá»›i Streamlit Community Cloud hoáº·c Hugging Face Spaces. Náº¿u cháº¡y trong Google Colab, Æ°u tiÃªn dÃ¹ng Gradio thay vÃ¬ Streamlit.")
